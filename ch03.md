# 视频编码概念

## 3.1 引言

**compress vb.: to squeeze together or compact into less space; condense**  
**compression noun: the act of compression or the condition of being compressed**

压缩是将数据压缩成更少 bit 的行为过程。视频压缩(视频编码)是将数字视频转换成适合传输或存储的格式的过程,同时通常会减少比特数。原始视频(未压缩视频)通常需要非常大的比特率，如第二章中的 216Mbit/s。因此，压缩对于数字视频的实际存储和传输是必要的。

压缩涉及一对互补的系统，一个压缩器(编码器)和一个解压器(解码器)。编码器在传输或存储之前，将源数据转换成占用较少比特数的压缩形式，解码器将压缩形式转换回原始视频数据。编码器/解码器对通常被描述为编解码器(编解码器)(图 3.1)。

![Figure 3.1 Encoder/Decoder](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.1.png?raw=true)

数据压缩是通过消除冗余来实现的，即消除那些数据的重建并不是必须的组件。数据的许多类型包含统计冗余，并且可以使用无损压缩进行有效压缩，这种情况，解码器端输出的重建数据是原始数据的完美副本。不幸的是，图像和视频信息的无损压缩只能提供中等程度的压缩。无损图像压缩标准(例如JPEG-LS)能够实现的最大压缩率是3-4倍左右。有损压缩对于实现高压缩率是由必要的。在有损压缩系统中，解压缩后的数据与原数据不相同，并且以视觉质量损失为代价来实现更高的压缩比。有损视频压缩系统基于去除主观冗余的原理，即图像或视频序列中的元素可以在不显著影响观看者对视觉质量的感知情况下被去除。

大多数视频编码方法利用时间和空间冗余来实现压缩。在时域中，几乎同时被捕获的视频帧之间通常高度的相似性或相关性。时间上相邻的帧，即时间顺序上的连续帧，通常高度相关，特别是在时间采样率或帧率高的情况下。在空间域中，彼此接近的像素（样本）之间通常存在高度相关性，即相邻样本的值通常非常相似（图3.2）。

![Figure 3.2 Spatial and temporal correlation in a video sequence](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.2.PNG?raw=true)

H.264高级视频编码标准与其他流行的压缩格式（如MPEG-2视频、MPEG-4视频、H.263、VC-1等）共享许多共同的特性。这些格式中的每一种都是基于使用预测和/或基于块的运动补偿、变换、量化和熵编码的编解码器“模型”。在这一章中，我们研究了该模型的主要组成部分，从预测模型开始，包括帧内预测、运动估计和运动补偿，接着是图像变换、量化、预测编码和熵编码。本章最后介绍了基本模型的“演变”，接着介绍了对图像样本块进行编码和解码的过程。

## 3.2 Video CODEC

视频编解码器（图 3.3）将源图像与视频序列编码为压缩形式，并对其进行解码以产生源序列的副本或近似值。如果解码的视频序列与原视频序列相同，则编码过程是无损的；如果解码序列与原始序列不同，则该过程是有损的。

![Figure 3.3 Video encoder block diagram](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.3.PNG?raw=true)

编解码器通过**模型**表示原视频序列，这是一种高效的编码表示，可用于重建视频数据的近似值。理想情况下，模型应该使用尽可能少的比特和尽可能高的保真度来表示序列。压缩效率和高质量这两个目标通常是冲突的，即较低的压缩比特率通常在解码器处产生降低的图像质量。

视频编码器（图3.3）由三个主要功能单元组成：**预测模型**、**空间模型**和**熵编码器**。预测模型的输入是未压缩的原始视频序列。预测模型试图通过利用相邻视频帧和/或相邻图像样本之间的相似性来减少冗余，通常通过构建当前视频帧或视频数据块的预测。在 H.264/AVC 中，根据当前帧或一个或多个先前和/或未来帧中的数据形成预测。它是通过相邻图像样本进行空间外推、帧内预测或通过补偿帧间差异、帧间或运动补偿预测来创建的。预测模型的输出是通过从实际的当前帧减去预测而产生的残余帧，以及指示帧内预测类型或描述如何补偿运动的一组模型参数。

残差帧形成了空间模型的输入，利用残差帧中的局部样本之间的相似性来减少空间冗余。在 H.264/AVC 中，这是通过对残余样本应用变换并量化结果来实现的。变换将样本转换为另一个域，在该域中它们由变换系数表示。系数被量化以去除不重要的值，留下少量的重要系数，其提供剩余帧的更紧凑表示。空间模型的输出是一组量化的变换系数。

预测模型的参数（即帧内预测模式或帧间预测模式和运动矢量）、以及空间模型（即系数）由熵编码器压缩。这消除了数据中的统计冗余，例如用短二进制码表示通常出现的向量和系数。熵编码器产生可被传输和/或存储的压缩比特流或文件。压缩序列由编码预测参数、编码残差系数和头信息组成。

视频解码器从压缩比特流重构视频帧。通过上解码器对系数和预测参数进行解码，然后对空间模型进行解码以重构残差帧的版本。解码器使用预测参数以及先前解码的图像像素来创建当前帧的预测，并通过将剩余帧添加到该预测中的重构帧本身。

## 3.3 预测模型

要处理的数据是当前帧或场中的一组图像样本。预测模型的目标是通过形成数据的预测并从当前数据中减去该预测来降低冗余。预测可能来自先前编码的帧(时间预测)或同一帧中先前编码的图像样本（空间预测）。该过程的输出是一组残差或差分样本，预测过程越精确，残差中包含的能量就越少。残差被编码并发送到解码器，解码器重建相同的预测，以便它可以添加解码残差并重构当前帧。为了解码器能够创建相同的预测，编码器必须使用解码器可用的数据，即已经编码和发送的数据来形成预测。

### 3.3.1 时域预测

预测帧是从一个或多个过去、将来的帧（称为参考帧）创建出的。通常可以通过补偿参考帧和当前帧之间的运动来提高预测精读。

#### 3.3.1.1 从之前帧预测

时间预测最简单方法是使用前一帧作为当前帧的预测器。一个视频序列的两个连续帧如图 3.4 和图 3.5 所示。第 1 帧作为第 2 帧的预测器，从当前帧(第 2 帧)减去预测器(第 1 帧)形成的残差如图 3.6 所示。在该图像中，中灰色表示差值为零，而浅灰色或深灰色分别对应于正差值和负差值。简单预测的明显问题是，在剩余帧（由亮区和暗区表示）中仍然存在大量能量，这意味着在时间预测之后仍然有大量信息要压缩。大部分剩余能量是由于两针之间的物体运动引起的，通过补偿两帧之间的运动可以形成更好的预测。

![Figure 3.4 Frame 1](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.4.PNG?raw=true)

![Figure 3.5 Frame 2](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.5.PNG?raw=true)

![Figure 3.6 Difference](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.6.PNG?raw=true)

#### 3.3.1.2 运动引起的变换

视频帧之间变换的原因包括运动、未覆盖区域和光照变化。运动类型包括刚性物体运动（例如移动的汽车）、可变性物体运动（例如说话的人）和相机运动（例如平移、倾斜、变焦和旋转）。未覆盖区域可能是被移动物体覆盖的场景背景的一部分。除了未覆盖区域和光照变化之外，这些差异对应于帧之间的像素移动。可以估计连续帧之间的每个像素的轨迹，产生称之为光流的像素轨迹场。图 3.7 显示了图 3.4 和图 3.5 框架的光流场。完整的场包括每个像素位置的流矢量，但是为了清楚起见，对场进行了子采样，以便仅显示每 2 个像素的矢量。

![Figure 3.7 Optical flow](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.7.PNG?raw=true)

如果准确地知道光流场，则可以沿着光流矢量从参考帧移动每个像素来形成对当前帧的大多数像素的准确预测。然而，这不是一种实用的运动补偿方法，原因有几个。光流的精确计算是非常计算密集的，因为更精确的方法会对每个像素都使用迭代过程，并且对于解码器重建预测帧，将有必要将每个像素的光流矢量发送到解码器，从而产生大量传输数据并降低小残差的优点。

#### 3.3.1.3 基于块的运动估计与补偿

一种实用并且被广泛使用的运动补偿方法是补偿当前帧的矩形部分或“块”的运动。对当前帧中的每个 MxN 样本块执行以下步骤：

* 搜索参考帧中的某个区域（过去或未来帧），以找到近似的 MxN 采样区域。可通过将当前帧中的 MxN 块与搜索区域中的一些或所有可能的MxN 区域（例如，以当前块位置为中心的区域）进行比较，并找到给出“最佳”匹配的区域来执行该搜索。一种流行的匹配准则是从当前的 MxN 块中减去候选区域所形成的残差中的能量，从而选择残差能量最小的候选区域作为最佳匹配。这种寻找最佳匹配的过程称为**运动估计**。  
* 所选的候选区域成为当前 MxN 块的预测器（运动补偿预测），并且从当前块中减去该候选区域形成剩余 MxN 块（**运动补偿**）。  
* 对剩余块进行编码和发送，并且还发送当前块与候选区域（**运动矢量**）的位置之间的偏移。  

解码器使用接收到的运动矢量来重新创建预测器区域。它对剩余块进行解码，将其添加到预测器中，并重建原始块的版本。

基于块的运动补偿是有许多原因的。它相对简单且易于计算，适合于矩形视频帧和基于块的图像变换（如离散余弦变换），为许多视频序列提供了合理有效的时间模型。但也有一些缺点。例如，“真实”对象很少有与矩形边界匹配的整齐边缘，对象通常在帧之间以小数点的像素位置移动，并且许多类型的对象运动很难使用基于块的方法进行补偿，例如可变形对象、旋转、扭曲和复杂运动（如烟云）。尽管存在这些缺点，基于块的运动补偿仍然是当前所有视频编码标准所使用的时间预测模型的基础。

#### 3.3.1.4 宏块的运动补偿预测

在包括MPEG-1、MPEG-2、MPEG-4、H.261、H.263和H.264在内的许多重要视频编码标准中，与帧的16×16像素区域相对应的宏块，是用于运动补偿预测的基本单元。对于流行的 420 格式的源视频材料（第2章），宏块的组织如图 3.8 所示。源帧的 16×16 像素区域由四个 8×8 采样块中排列的256个亮度样本、一个 8×8 块中的 64 个红色色度样本和一个 8×8 块中的 64 个蓝色色度样本表示，总共给出六个 8×8 块。H.264/AVC编解码器以宏块为单位处理每个视频帧。

![Figure 3.8 Macroblock (4:2:0)](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.8.PNG?raw=true)

**运动估计：**  

宏块的运动估计涉是在参考帧中找到与当前宏块匹配的 16×16 采样区域。参考帧是来自序列的先前编码的帧，在显示顺序中它可能在当前帧之前或之后。搜索以当前宏块位置为中心的参考帧中的搜索区域，并选择搜索区域中使匹配标准最小化的 16×16 区域作为“最佳匹配”（图 3.9 ）。

![Figure 3.9 Motion estimation](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.9.PNG?raw=true)

**运动补偿：**  

从当前宏块中减去参考帧中所选择的“最佳”匹配区域的亮度和色度样本以产生剩余宏块，该剩余宏块与描述最佳匹配区域相对于当前宏块位置的位置的运动矢量一起编码和传输。  

基于基本的运动估计和补偿过程，有很多变种。参考帧可以是时间顺序上的先前帧、未来帧或来自两个或多个先前编码帧的预测的组合。如果选择未来帧作为参考，则必须在当前帧之前对该帧进行编码，即编码帧必须与视频帧序列顺序不同。如果参考帧和当前帧之间存在显著变化，例如场景变化或未覆盖区域，在没有运动补偿的情况下对宏块进行编码可能更有效，因此编码器可能为每个宏块选择使用帧内预测的帧内模式编码或具有运动补偿预测的帧间模式编码。视频场景中的运动对象很少遵循“整齐”的16×16像素边界，因此使用可变块大小进行运动估计和补偿可能更有效。对象可以在帧之间移动小数像素，例如在水平方向上移动2.78像素而不是2.0像素，并且可以通过在搜索这些位置以获得最佳匹配之前将参考帧内插到子像素位置来形成更好的预测。

#### 3.3.1.5 运动补偿块大小

一个视频序列中的两个连续帧如图 3.10 和图 3.11 所示。从第 2 帧减去第 1 帧而不进行运动补偿，以产生剩余帧（图 3.12）。通过对每一个 16×16 宏块进行运动补偿，可以降低残差中的能量（图3.13）。每 8×8块 而不是每 16×16 宏块的运动补偿进一步降低了剩余能量（图3.14），每 4×4 块的运动补偿给出的剩余能量最小（图3.15）。这些例子表明，较小的运动补偿块大小可以产生更好的运动补偿结果。然而，较小的块大小导致复杂性增加，需要执行更多的搜索操作，并且需要传输的运动矢量的数量增加。发送每个运动矢量需要传输比特，矢量的额外开销可能超过减少剩余能量的好处。一种有效的折衷方法是使块大小适应图片特征，例如在帧的平坦均匀区域中选择大块大小，并在高细节和复杂运动区域周围选择小块大小（第6章）。

![Figure 3.10 Frame 1](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.10.PNG?raw=true)

![Figure 3.11 Frame 2](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.11.PNG?raw=true)

![Figure 3.12 Residual : no motion compensation](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.12.PNG?raw=true)

![Figure 3.13 Residual : 16 × 16 block size](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.13.PNG?raw=true)

![Figure 3.14 Residual : 8 × 8 block size](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.14.PNG?raw=true)

![Figure 3.15 Residual : 4 × 4 block size](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.15.PNG?raw=true)


#### 3.3.1.6 亚像素运动补偿

图 3.16 显示了参考框架部分的特写视图。在某些情况下，根据参考帧中的内插样本位置进行预测可以形成更好的运动补偿预测。在图 3.17 中，参考区域像素被内插到半像素位置，并且通过搜索内插的样本可以找到当前宏块的更好匹配。亚像素运动估计和补偿包括搜索亚像素插值位置和整数像素位置，并选择最佳匹配位置和最小化剩余能量。图 3.18 显示了四分之一像素运动估计的概念。在第一阶段，运动估计在整数像素网格（圆）上找到最佳匹配。编码器搜索紧靠此最佳匹配（正方形）的半像素位置，以查看是否可以改进匹配，如果需要，则搜索紧靠最佳半像素位置（三角形）的四分之一像素位置。从当前块或宏块中减去整数、半像素或四分之一像素位置的最终匹配。

![Figure 3.16 Close-up of reference region](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.16.PNG?raw=true)

![Figure 3.17 Reference region interpolated to half-pixel positions](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.17.PNG?raw=true)

![Figure 3.18 Integer, half-pixel and quarter-pixel motion estimation](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.18.PNG?raw=true)

图3.19中的残差是使用4×4像素的块大小通过半像素插值产生的，并且残差能量小于图3.15。这种方法可以通过在1/4像素网格上插值得到更小的残差来进一步扩展（图3.20）。一般而言，“更精细”插值提供更好的运动补偿性能，以增加复杂性为代价产生更小的残差。随着插值步长的增加，性能增益趋于减小。半像素内插比整数像素运动补偿有显著的增益，四分之一像素内插有适度的进一步改进，八分之一像素内插有少量的进一步改进，以此类推。

![Figure 3.19 Residual : 4 × 4 blocks, 1/2-pixel compensation](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.19.PNG?raw=true)

![Figure 3.20 Residual : 4 × 4 blocks, 1/4-pixel compensation](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.20.PNG?raw=true)

表3.1给出了通过亚像素插值实现的一些性能示例。从当前帧中减去运动补偿参考帧（序列中的前一帧），表中列出了由绝对误差之和（SAE）近似的残差能量。SAE越低，运动补偿性能越好。在每种情况下，与整数像素补偿相比，亚像素运动补偿提供了改进的性能。从整数到半像素的改进比从半像素到四分之一像素的进一步改进更为显著。序列“Grasses”具有高度复杂的运动，特别难以进行运动补偿，因此具有较大的SAE；'“小提琴”和“Carphone”不太复杂，运动补偿产生的SAE值较小。

Table 3.1 SAE of residual frame after motion compensation, 16 × 16 block size

| Sequence | No motion compensation | Integer-pel | Half-pel | Quarter-pel |  
| :---: | :---: | :---: | :---: |  :---: | 
| violin, QCIF | 171945 | 153475 | 128320 | 113744 |  
| ‘Grasses’, QCIF | 248316 | 245784 | 228952 | 215585 |  
| ‘Carphone’, QCIF | 102418 | 73952 | 56492 | 47780 |  

使用1/4像素插值搜索匹配的4×4块要比不使用插值搜索16×16块复杂得多。除了额外的复杂性之外，还有一个编码惩罚，因为每个块的向量必须被编码并传输到接收器，以便正确地重建图像。随着块大小的减小，必须传输的向量的数目增加。需要更多位来表示1/2或1/4像素向量，因为向量的小数部分（例如0.25或0.5）必须与整数部分一起编码。图3.21绘制了与图3.13的残差一起传输的整数运动矢量。图3.20的残差所需的运动矢量绘制在图3.22中，其中有16倍的矢量，每个矢量由两个分数DX和DY表示，精度为1/4像素。因此，与更复杂的运动补偿方案相关联的压缩效率存在权衡，因为更精确的运动补偿需要更多比特来编码向量场，但是对残差进行编码的比特数较少，而较不精确的运动补偿要求向量场的比特数较少，而残差的比特数较多。使用复杂的插值滤波器可以提高亚像素插值算法的效率。

![Figure 3.21 Motion vector map : 16 × 16 blocks, integer vectors](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.21.PNG?raw=true)

![Figure 3.22 Motion vector map : 4 × 4 blocks, 1/4-pixel vectors](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.22.PNG?raw=true)

### 3.3.2 空间模型：帧内预测

从同一帧中先前编码的样本创建对当前图像样本块的预测。图3.23显示了当前帧中要预测的块（中心）。假设图像样本的块按光栅扫描顺序编码（并非总是这样），则上/左阴影块可用于帧内预测。这些块已经被编码并放置在输出比特流中。当解码器处理当前块时，阴影化的上/左块已经被解码并且可以用于重新创建预测。

![Figure 3.23 Intra prediction: available samples](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.23.PNG?raw=true)

人们提出了许多不同的帧内预测方法。H.264/AVC使用空间外推来创建块或宏块的帧内预测。图3.24显示了一般概念。通过从当前块的顶部和/或左侧外推样本来形成一个或多个预测。一般来说，最近的样本最有可能与当前块中的样本高度相关（图3.25），因此仅使用沿上边缘和/或左边缘的像素来创建预测块。一旦预测已经生成，就以与帧间预测类似的方式从当前块中减去它以形成残差。对残差进行变换和编码，并指示如何生成预测。第六章详细介绍了帧内预测。

![Figure 3.24 Intra prediction: spatial extrapolation](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.24.PNG?raw=true)

![Figure 3.25 2D autocorrelation function of image](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.25.PNG?raw=true)

## 3.4 图像模型

自然视频图像由采样值网格组成。由于相邻图像样本之间的高度相关性，自然图像很男按照原始形式压缩。图3.25 显示了自然视频的二维自相关函数（图3.4），其中每个位置的图像高度表示原始图像和自身空间移动副本之间的相似性。图像中心的峰值对应于零偏移。当空间移位的拷贝在任何方向上，从原始图像移开时，如图所示，该函数衰减，并且渐变斜率指示局部邻域内的图像样本高度相关。

如图 3.20 所示的运动补偿残差图像具有自相关函数(图 3.26)，该函数随着空间偏移的增加二迅速下降，表明相邻样本之间的相关性较弱。有效的运动补偿或帧内预测降低了残差中的局部相关性，使其比原始视频帧更易于压缩。图像模型的功能使进一步去相关图像或残差数据，并将其转换为可以使用熵编码器有效亚索的形式。实际的图像模型通常有三个主要的组成部分，变换来消除和压缩数据，量化来降低变换数据的精度，重新排序来排列数据以将重要值组合在一起。

![Figure 3.26 2D autocorrelation function of residual](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.26.PNG?raw=true)

### 3.4.1 预测图像编码

运动补偿是预测编码的示例，其中编码器基于先前或未来帧创建当前帧的区域的预测，并从当前区域减去该预测以形成残差。如果预测成功，则残差中的能量低于原始帧中的能量，并且残差可以用较少的比特来表示。

预测编码是早期图像压缩算法的基础，是 H.264 帧内编码的重要组成部分，参见第 3.3.2 节和第 6 章。空间预测涉及从相同图像或帧中先前传输的样本预测图像样本或区域，有时被描述为“差分脉冲编码调制(DPCM)”，这是从电信系统中差分编码 PCM 样本的方法中借用的术语。

图3.27显示了要编码的像素X。如果帧是按光栅顺序处理的，那么当前行和前一行中的像素A、B和C在编码器和解码器中都可用，因为它们应该在X之前已经被解码。编码器基于先前编码的像素的一些组合形成对X的预测，从X减去该预测，并对残差（减去的结果）进行编码。解码器形成相同的预测，并将解码后的残差相加以重构像素。

![Figure 3.27 Spatial prediction (DPCM)](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.27.PNG?raw=true)

> **示例**
> 
> 编码预测 P(X) = (2A + B + C)/4  
> 残差 R(X) = X - P(X) 被编码并传输  
> 解码器解码 R(X) 并形成相同的预测：`P(X) = (2A + B + C)/4`  
> 重建像素 X = R(X) + P(X)  

如果编码过程是有损的，即如果残差被量化-参见第3.4.3节，那么由于编码过程中的损失，解码的像素A′、B′和C′可能与原始的A、B和C不相同，因此上述过程可能导致编码器和解码器之间的累积失配或“漂移”。为了避免这种情况，编码器应该自己解码剩余的R'（X）并重建每个像素。因此，编码器使用解码像素A′、B′和C′来形成预测，即在上述示例中P（X）=（2A′+B′+C'）/4。这样，编码器和解码器使用相同的预测P（X），并且避免了漂移。

这种方法的压缩效率取决于预测P（X）的精度。如果预测是准确的，即P（X）是X的近似值，那么剩余能量将很小。然而，预测期适用于对复杂图像的所有区域是不可能的；根据图像的局部统计来调整预测期可能获得更好的性能（例如，对于平坦纹理、强垂直纹理、强水平纹理的区域使用不同的预测器）。编码器必须向解码器指示预测器的选择，因此在有效的预测和向预测器的选择发送信号所需的额外比特之间存在折衷。

### 3.4.2 变换编码

#### 3.4.2.1 概述

图像或视频编解码器中的变换阶段的目的是将图像或运动补偿的残差数据转换到另一域，即变换域。变换的选择取决于许多条件：

1. 变换域中的数据应该去相关，即在最小的相互依赖范围内分离出组件并且紧凑（即变换数据中的大部分能量应该集中到少量值中）。  
2. 这种变换是可逆的。
3. 变换应具有计算可处理性。例如，低内存要求、可使用有限精度算法实现、算术运算次数少等。

许多变换已经被提出用于图像和视频压缩，最流行的变换往往分为两类，基于块的和基于图像的。基于块的变换的例子包括Karhunen-Loeve变换（KLT）、奇异值分解（SVD）和一直流行的离散余弦变换（DCT）及其近似。其中每一个都对 NxN 图像块或残差样本进行操作，因此图像以块为单位进行处理。块变换具有较低的内存需求，非常适合基于块的运动补偿残差的压缩，但往往会收到块边缘伪影（块效应）的影响。基于图像的变换操作整个图像或帧，或者称为“平铺”的图像的很大一部分。最流行的图像变换是离散小波变换，DWT 或仅仅是“小波”。图像变换（如DWT）已被证明比用于静止图像压缩的块变换执行得更好，但它们往往具有更高的内存要求，因此整个图像或块作为一个单元进行处理，并且它们不一定与机遇块的运动补偿很好地“适配”。DCT 和 DWT 都是 MPEG-4 视频中的特征，与 H.264 中包含的 DCT 近似，并且在下面的部分中进一步讨论。

#### 3.4.2.2 DCT

离散余弦变换（DCT）对 X（NxN 个样本块，通常是图像样本或预测后的残差）进行运算，以创建Y（NxN 个系数块）。离散余弦变换及其逆变换的作用，可以用变换矩阵 a 来描述。

**Example 2 Image block and DCT coefficients**

图3.30显示了选择了4×4块的图像，图3.31显示了特写中的块以及DCT系数。在DCT域中表示块的优点并不明显，因为数据量没有减少；我们需要存储16个DCT系数，而不是16个像素值。当从系数子集重构块时，DCT的有用性变得清晰。

![Figure 3.30 Image section showing 4 × 4 block](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.30.PNG?raw=true)

![Figure 3.31 Close-up of 4 × 4 block; DCT coefficients](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.31.PNG?raw=true)

![Figure 3.32 Block reconstructed from (a) 1, (b) 2, (c) 3, (d) 5 coefficients](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.32.PNG?raw=true)

将所有系数设置为零，但最重要的系数（0,0）被描述为“DC”系数，并执行IDCT给出图3.32（a）所示的输出块，即原始像素值的平均值。计算两个最重要系数的IDCT得出图3.32（b）所示的方框。在计算IDCT之前添加更多的系数，可以逐步更精确地重建原始块，并且在包括五个系数时（图3.32（d）），重建块与原始块的匹配程度相当接近。因此，可以从16个DCT系数的子集重构块的近似副本。例如，通过量化（见第3.4.3节）移除具有不显著大小的系数，使得图像数据能够以减少的系数值数量来表示，而牺牲了一些质量损失。

#### 3.4.2.3 小波变换

在图像压缩中流行的“小波变换”是基于一组系数相当于离散小波函数的滤波器。变换的基本操作如下，应用于包含N个样本的离散信号。对信号应用一对滤波器，将其分解为低频带（L）和高频带（H）。每个频带以二的因子进行二次采样，因此两个频带每个包含N/2个样本。如果正确选择过滤器，这种操作是可逆的。

该方法可扩展应用于二维信号，如强度图像（图3.33）。使用低通和高通滤波器（Lx和Hx）对2D图像的每一行进行滤波，并且对每个滤波器的输出进行二倍的下采样以产生中间图像L和H。L是在x方向上经过低通滤波和下采样的原始图像，H是在x方向上经过高通滤波和下采样的原始图像。接下来，使用低通和高通滤波器Ly和Hy对这些新图像的每一列进行滤波，并以2的因子进行下采样，以生成四个子图像LL、LH、HL和HH。这四个“子带”图像可以组合在一起，以创建与原始图像具有相同样本数的输出图像（图3.34）LL'是原始图像，在水平和垂直方向进行低通滤波，并以二的因子进行二次采样HL'在垂直方向上进行高通滤波并包含残余垂直频率，'LH'在水平方向上进行高通滤波并包含残余水平频率，'HH'在水平和垂直方向上进行高通滤波。在它们之间，四个子带图像包含原始图像中存在的所有信息，但LH、HL和HH子带的稀疏特性使它们易于压缩。

![Figure 3.33 Two-dimensional wavelet decomposition process](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.33.PNG?raw=true)

![Figure 3.34 Image after one level of decomposition](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.34.PNG?raw=true)

在图像压缩应用中，上述二维小波分解再次应用于“LL”图像，形成四个新的子带图像。生成的低通图像（始终是左上方的子带图像）经过迭代过滤以创建子带图像树。图3.35显示了两个分解阶段的结果，图3.36显示了五个分解阶段的结果。高频子带图像中的许多样本（系数）接近于零，此处显示为接近黑色，并且可以通过在传输之前移除这些不重要的系数来实现压缩。在解码器处，通过重复上采样、滤波和加法重构原始图像，操作顺序如图3.33所示。

![Figure 3.35 Two-stage wavelet decomposition of image](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.35.PNG?raw=true)

![Figure 3.36 Five-stage wavelet decomposition of image](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.36.PNG?raw=true)

### 3.4.3 量化

量化器将具有值 X 的范围的信号映射到具有减小的值 Y 的范围的量化信号。由于可能值的范围较小，因此应该可以用比原始值更小的比特来表示量化信号。**标量量化器**将输入信号的一个样本映射到一个量化输出值，**向量量化器**将一组输入样本“向量”映射到一组量化值。

#### 3.4.3.1 标量量化器

标量量化的一个简单示例是将分数舍入到最接近的整数的过程，即映射是从R到Z。该过程是有损的（不可逆的），因为无法从舍入整数中确定原始分数的精确值。

均匀量化器的更一般示例为：FQ = round(X/QP) Y = FQ * QP 其中QP是量化“步长”。量化输出电平以均匀的QP间隔隔开，如以下示例所示。

图3.37显示了标量量化器的两个示例，一个是输入和输出值之间具有均匀映射的线性量化器，另一个是具有约为零的“死区”的非线性量化器，其中小值输入映射为零.

![Figure 3.37 Scalar quantizers: linear; non-linear with dead zone](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.37.PNG?raw=true)

在图像和视频压缩编解码器中，量化操作通常由两部分组成，编码器中的前向量化器FQ和解码器中的“逆量化器”或“重缩放器”（IQ）。一个关键参数是连续重新缩放值之间的步长QP。如果步长大，则量化值的范围小，因此可以有效地表示，并因此在传输期间高度压缩，但是重新缩放的值是原始信号的粗略近似值。如果步长较小，则重新缩放的值与原始信号的匹配更紧密，但较大的量化值范围会降低压缩效率。

量化可用于在应用诸如DCT或小波变换之类的变换之后降低图像数据的精度，并移除诸如近零DCT或小波系数之类的不重要值。图像或视频编码器中的前向量化器设计用于将不重要的系数值映射为零，同时保留少量重要的非零系数。因此，前向量化器的输出通常是量化系数的“稀疏”阵列，主要包含零。

#### 3.4.3.2 矢量量化器

矢量量化器将一组输入数据（例如图像样本块）映射到单个值（码字），并且在解码器处，每个码字映射到原始输入数据集的近似值，即“矢量”。向量集存储在码本中的编码器和解码器处。矢量量化在图像压缩中的典型应用如下：

1. 将原始图像划分为N×N像素块等区域。  
2. 从码本中选择与当前区域尽可能匹配的向量。
3. 向解码器发送标识所选向量的索引。
4. 在解码器处，使用所选向量重建区域的近似副本。

![Figure 3.38 Vector quantization](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.38.PNG?raw=true)

基本系统如图3.38所示。这里，量化应用于图像（空间）域，即，图像样本组被量化为向量，但它同样可以应用于运动补偿和/或变换数据。矢量量化器设计中的关键问题包括码书的设计和有效搜索码书以找到最优矢量。

### 3.4.4 重排序和零编码

在存储和传输之前，需要对量化变换系数进行尽可能紧凑的编码。在基于变换的图像或视频编码器中，量化器的输出是包含少量非零系数和大量零值系数的稀疏阵列。在熵编码之前，对非零系数进行重新排序并对零系数进行有效编码。

#### 3.4.4.1 DCT 

**Coefficient distribution**

图像块或残余样本的有效DCT系数通常是DC（0,0）系数周围的“低频”位置。

图3.39绘制了QCIF剩余帧中8×8块中每个位置处非零DCT系数的概率（图3.6）。非零DCT系数聚集在左上角（DC）系数周围，分布在水平和垂直方向上大致对称。

![Figure 3.39 8 × 8 DCT coefficient distribution (frame)](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.39.PNG?raw=true)

图3.41描绘了剩余场的非零DCT系数的概率（图3.40）；这里，系数聚集在DC位置周围，但“倾斜”，即更多非零系数出现在绘图的左边缘。这是因为由于垂直方向上的子采样，场图像在垂直轴上可能具有更强的高频分量，从而导致与垂直频率相对应的更大的DCT系数（图3.28）。

![Figure 3.40 Residual field picture](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.40.PNG?raw=true)

![Figure 3.41 8 × 8 DCT coefficient distribution (field)](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.41.PNG?raw=true)

**Scan**

在量化之后，块的DCT系数被重新排序以将非零系数分组在一起，从而能够有效地表示剩余的零值量化系数。最佳重排序路径或扫描顺序取决于非零DCT系数的分布。对于分布类似于图3.39的典型帧块，合适的扫描顺序为从DC或左上角系数开始的锯齿形。从DC系数开始，按照图3.42所示的顺序将每个量化系数复制到一维数组中。非零系数往往在重新排序的数组开始时分组在一起，然后是长的零序列。

![Figure 3.42 Zigzag scan example : frame block](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.42.PNG?raw=true)

![Figure 3.43 Zigzag scan example : field block](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.43.PNG?raw=true)

对于场块，锯齿扫描可能并不理想，因为存在倾斜系数分布，如图3.41所示，而对于某些场块，如图3.43所示的修改后的扫描顺序可能更有效，其中块左侧的系数在右侧之前进行扫描。

**Run-Level Encoding**

重新排序过程的输出是一个数组，该数组通常在开始处包含一个或多个非零系数簇，后跟零系数串。可以对大量零值进行编码以更紧凑地表示它们。重新排序的系数数组表示为（run，level）对，其中run表示非零系数之前的零数，level表示非零系数的大小。

**示例**：1. 输入序列：16,0,0,−3,5,6,0,0,0,0,−7,. . .2. 输出值：(0,16),(2,−3),(0,5),(0,6),(4,−7). . .3. 熵编码器将这些输出值中的每一个（运行级对）编码为单独的符号。

更高频率的DCT系数通常量化为零，因此重新排序的块通常以一系列零结束。需要一种特殊情况来指示块中的最终非零系数。如果使用“二维”运行级编码，则每个运行级对均按上述方式编码，且单独的代码符号“last”表示非零值的结束。如果使用“三维”运行级别编码，则每个符号编码三个量：运行、级别和最后一个。在上述示例中，如果–7是最终非零系数，则三维值为：
(0, 16, 0), (2, −3, 0), (0, 5, 0), (0, 6, 0), (4, −7, 1)

最终代码中的1表示这是块中最后一个非零系数。

#### 3.4.4.2 Wavlet

**Coefficient distribution**

图3.36显示了2D小波系数的典型分布。图右下方较高子带中的许多系数接近零，可以量化为零，而不会显著降低图像质量。非零系数往往与图像中的结构有关；例如，小提琴弓在所有水平和对角子带中显示为清晰的水平结构。当低频子带中的系数为非零时，高频子带中相应位置的系数也很可能为非零。我们可以考虑一个非零量化系数的“树”，从低频子带中的“根”开始。图3.44说明了这一概念。层1的LL频带中的单个系数在层1的每个其他频带中具有一个对应系数，即，这四个系数对应于原始图像中的相同区域。第1层系数位置映射到第2层每个子带中的四个对应子系数位置。回想一下，第2层子带的水平和垂直分辨率是第1层子带的两倍。

![Figure 3.44 Wavelet coefficient and ‘children’](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.44.PNG?raw=true)

**Zerotree encoding**

在熵编码之前，希望尽可能紧凑地编码非零小波系数。实现这一点的有效方法是从分解的最低或根级别开始对每个非零系数树进行编码。对最低层的系数进行编码，然后对下一层的子系数进行编码，依此类推。编码过程将继续，直到树达到零值系数。零值系数的其他子项本身可能为零，因此剩余子项由标识零树（zerotree）的单个代码表示。解码器从每棵树的根开始重建系数映射；非零系数被解码和重构，当达到零树码时，所有剩余的“子”都被设置为零。这是嵌入式零树（EZW）小波系数编码方法的基础。在编码过程中包括额外的可能性，其中零系数后面可以跟（a）零树，如前所述，或者（b）非零子系数。情况（b）并不经常出现，但通过满足情况（b）偶尔出现的情况，重建图像质量略有改善。

## 3.5 熵编码

熵编码将表示视频序列元素的一系列符号转换成适于传输或存储的压缩比特流。输入符号可包括量化变换系数、运动级别或者按第 3.4.4 节所述编码的非零系数、具有整数或亚像素分辨率的运动矢量、指示序列中重新同步点的标记码、宏块头、图片头、序列头等和补充信息；边信息对于正确解码不是必需的。

### 3.5.1 预测编码

图片中的局部区域的某些符号是高度相关的。例如，相邻帧内编码块的像素的平均值或 DC 值可能非常相似，相邻运动矢量可能具有相似的 x 和 y 位移等。通过从先前编码的数据预测当前块或宏块的元素并编码预测值和实际值之间的差异，可以提高编码效率。

块或宏块的运动矢量指示到先前编码帧中的预测参考的偏移。相邻块或宏块的向量通常是相关的，因为物体运动可能跨越帧的大区域。对于较小的块大小，例如 4x4 块向量(图3.22)或有较大运动幅度的物体，尤其如此。可以通过从先前编码的向量预测每个运动向量来改进运动向量场的压缩。当前宏块 X 的向量的简单预测是水平相邻的宏块 A（图3.45）；或者，可以使用三个或更多先前编码的向量来预测宏块 X 处的向量，例如图 3.45 中的A、B 和 C。对预测运动矢量和实际运动矢量之间的差，即运动矢量差或MVD进行编码和传输。

![Figure 3.45 Motion vector prediction candidates](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.45.PNG?raw=true)

量化参数或量化器步长控制压缩效率和图像质量之间的权衡。在实时视频编解码中，可能需要修改编码帧内的量化，例如改变压缩比，以便将编码比特率与传输信道速率匹配。在连续编码的宏块之间，通常只需少量改变参数即可。修改后的量化参数必须用信号通知解码器，并且代替发送新的量化参数值，可以优选发送增量或差值，例如 +/-1或+/-2，表示所需的更改。编码一个小的增量值比编码一个全新的量化参数需要更小的位。

### 3.5.2 变长编码

可变长度编码器将输入符号映射到一系列码子、可变长度代码或 VLC。每个符号映射到一个码字，码字可能具有不同的长度，但每个码字必须包含整数位数。频繁出现的符号用短 VLC 表示，儿不太常见的符号用长 VLC 表示。在足够多的编码符号上，这会导致数据压缩。

#### 3.5.2.1 Huffman coding

哈夫曼编码根据不同符号的出现概率为每个符号分配 VLC。根据 Huffman 在 1952 年提出的原始方案，需要计算每个符号的出现概率并构造一组可变长度码字。这一过程将通过两个例子加以说明。  

**Example 1:Huffman coding, Sequence 1 motion vectors**

需要对视频序列 1 的运动矢量差分数据(MVD)进行编码。表 3.2 列出了编码序列中最常见的运动矢量的概率及其信息内容 log2(1/p)。为了实现最佳压缩，每个值都应该精确地用 log2(1/p)位表示。 0 是最常见的值，较大运动矢量的概率下降。该分部代表包含中等运动的序列。

Table 3.2 Probability of occurrence of motion vectors in sequence 1

| Vector | Probability p | log2(1/p) |  
| :----: | :-----: | :----: |  
| -2 | 0.1 | 3.32 |   
| -1 | 0.2 | 2.32 |  
| 0 | 0.4 | 1.32 |  
| 1 | 0.2 | 2.32 |  
| 2 | 0.2 | 3.32 |  

1. 生成哈夫曼代码树

要为这组数据生成哈夫曼代码表，请执行一下迭代过程：1. 按概率递增的顺序排列数据列表。2. 将两个概率最低的数据组合成一个“节点”，并将数据项的联合概率分配给该节点。3. 按概率递增的顺序重新排列其余数据项和节点，并重复步骤2。

重复此过程，直到有一个“根”节点包含“下面”列出的所有其他节点和数据项。该程序如图3.46所示。

![Figure 3.46 Generating the Huffman code tree: Sequence 1 motion vectors](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.46.PNG?raw=true)

| Original list | The data items are shown as square boxes. Vectors (−2) and (+2) have the lowest probability and these are the first candidates for merging to form node ‘A’. |  
| :----: | :----: |   
| Stage 1: | The newly-created node ‘A’, shown as a circle, has a probability of 0.2, from the combined probabilities of (−2) and (2). There are now three items with probability 0.2. Choose vectors (−1) and (1) and merge to form node ‘B’. |  
| Stage 2: | A now has the lowest probability (0.2) followed by B and the vector 0; choose A and B as the next candidates for merging to form ‘C’. |  
| Stage 3: | Node C and vector (0) are merged to form ‘D’. |  
| Final tree | The data items have all been incorporated into a binary ‘tree’ containing five data values and four nodes. Each data item is a ‘leaf’ of the tree. |  

2. 编码

二叉树的每个叶子都映射到一个可变长度的代码。为了找到这段代码，将树从根节点(在本例中为 D)遍历到叶或数据项。如图 3.46 的最后一课树所示，每个分支的代码后面都会附加一个 0 或 1,0表示上分支，1 表示下分支，给出一下代码集（表3.3）。

Table 3.3 Huffman codes for sequence 1 motion vectors

| Vector | Code | Bits (actual) | Bits (ideal) |  
| :----: | :----: | :------: | :-----: |  
| 0 | 1 | 1 | 1.32 |  
| 1 | 011 | 3 | 2.32 |  
| -1 | 010 | 3 | 2.32 | 
| 2 | 001 | 3 | 3.32 |  
| -2 | 000 | 3 | 3.32 |  

编码是通过为每个数据项传输适当的代码来实现的。请注意，生成树后，diam可能存储在查找表中。

高概率数据项被分配短代码，例如，最常见的向量'0'为 1 位。然而，向量(-2, 2, -1, 1)均被分配为 3 位代码，尽管 -1 和 1 的概率高于 -2 和 2。哈夫曼代码的长度(每个位整数位数)与 log2(1/p)给出的理想长度不匹配。没有任何代码包含任何其他代码作为前缀，这意味着，从左侧位读取时，每个代码都是唯一可解码的。

例如，向量系列（1，0，−2） 将作为二进制序列0111000传输。

3. 解码

为了解码数据，解码器必须具有哈夫曼代码树或查找表的本地副本。这可以通过发送查找表本身或者通过在发送编码数据之前发送数据和概率的列表来实现。每个唯一可解码的代码都会转换回原始数据，例如：1. `011`解码成`(1)` 2. `1`解码成`(0)` 3. `000`解码成`-2`。

**Example 2: Huffman coding, sequence 2 motion vectors**

对具有不同运动向量概率分布的第二序列重复上述过程会给出不同的结果。概率在表 3.4 中列出，并注意，零向量更可能出现在本例中，代码一个几乎没有移动的序列。

Table 3.4 Probability of occurrence of motion vectors in sequence 2

| Vector | Probability | log2(1/p) |  
| :----: | :---------: | :-------: |  
| -2 | 0.02 | 5.64 |  
| -1 | 0.07 | 3.84 |  
| 0 | 0.8 | 0.32 |  
| 1 | 0.08 | 3.64 |  
| 2 | 0.03 | 5.06 |  

图 3.47 给出了相应的哈夫曼树。由于概率的分布，树的形状发生了变化，这产生了一组不同的哈夫曼码，如表 3.5 所示。树中仍然有四个节点，比数据项的数量(5)少一个，就像哈夫曼编码一样。

![Figure 3.47 Huffman tree for sequence 2 motion vectors](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.47.PNG?raw=true)

Table 3.5 Huffman codes for sequence 2 motion vectors

| Vector | Code | Bits(actual) | Bits(ideal) |  
| :----: | :----: | :------: | :-----: |  
| 0 | 1 | 1 | 0.32 |  
| 1 | 01 | 2 | 3.64 |  
| -1 | 001 | 3 | 3.84 |  
| 2 | 0001 | 4 | 5.06 |  
| -2 | 0000 | 4 | 5.64 |  


如果概率分布是准确的，哈夫曼编码提供了原始数据的相对紧凑的表示。在这些示例中，频繁出现的（0）向量有效地表示为单个比特。然而，为了实现最佳压缩，由于两个序列的概率分布不同，因此需要为每个序列提供单独的代码表。对于序列2中的向量“0”，由于整数长度代码的要求而导致的潜在压缩效率损失非常明显，因为最佳比特数（信息内容）为0.32，但哈夫曼编码可实现的最佳比特数为1。

#### 3.5.2.2 基于预计算哈夫曼编码

哈夫曼编码过程对于实际的视频编解码器有两个缺点。首先，解码器必须使用与编码器相同的码字集。这意味着编码器需要在解码器能够解码比特流之前发送包含在概率表中的信息，但是该额外开销降低了压缩效率，特别是对于较短的视频序列。其次，生成哈夫曼树所需的大型视频序列的概率表在视频数据编码后才能计算，这可能会在编码过程中引入不可接受的延迟。由于这些原因，图像和视频编码标准根据“通用”视频材料的概率分布定义了码字集。以下两个预先计算的VLC表示例取自MPEG-4 Visual（Simple Profile）。

**转换系数（TCOEF）**

MPEG-4 Visual 使用量化系数的3-D编码，其中每个码字表示(run, level, last)的组合。总共有 102 个特定组合(run, level, last) 分配了 VLC，其中 26 个代码如表 3.6 所示。

Table 3.6 MPEG-4 Visual Transform Coefficient (TCOEF) VLCs : partial, all codes < 9 bits

| Last | Run | Level | Code |  
| :---: | :----: | :----: | :----: |  
| 0 | 0 | 1 | 10s |  
| 0 | 1 | 1 | 110s  |  
| 0 | 2 | 1 | 1110s  |  
| 0 | 0 | 2 | 1111s  |  
| 1 | 0 | 1 | 0111s  |  
| 0 | 3 | 1 | 01101s |  
| 0 | 4 | 1 | 01100s |  
| 0 | 5 | 1 | 01011s |  
| 0 | 0 | 3 | 010101s |  

进一步定义了 76 个 VLC，每个 VLC 的长度最多为 13 位。每个码字的最后一位是符号位"s"，表示解码系数的符号，其中 0 = 正，1 = 负。表中未列出的任何(run，level，last)组合都使用转义序列进行编码，转义序列进行编码，转义序列是一个特殊的转义码(0000011)，后跟一个描述 run、level和 last 值得 13 位固定长度代码。

表3.6中所示的一些代码在图 3.48 中以“树”形式表示。包含超过八个零的运行的码字无效，因此任何以000000000开头的码字。指示位流中的错误或可能的起始代码，该错误以长的零序列开始，发生在序列中的意外位置。所有其他比特序列都可以解码为有效代码。请注意，最小的代码分配给短运行和小级别，因为这些代码最常出现，例如代码“10”表示运行为0，级别为0+/−1。

![Figure 3.48 MPEG4 TCOEF VLCs (partial)](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.48.PNG?raw=true)

**Motion Vector Difference(MVD)**  

差分编码运动矢量(MVD)每个都编码为一对 VLC，一个用 x 分量，一个用于 y 分量。VLCs 表的一部分如表 3.7 所示。此处未显示另外 49 个 8-13 位厂的代码。请注意，最短代码表示较小的运动矢量差异，例如 MVD=0由一个位代码"1"表示。

Table 3.7 MPEG-4 Motion Vector Difference(MVD) VLCs

| MVD | Code |  
| :---: | :---: |  
| 0 | 1 |  
| +0.5 | 010 |  
| -0.5 | 011 |  
| +1  | 0010 |  
| -1  | 0011 |  
| +1.5 | 00010 |  
| -1.5 | 00011 |  
| +2   | 0000110 |   
| -2 | 0000111 |   
| +2.5 | 00001010 |  
| −2.5 | 00001011 |  
| +3 | 00001000 |  
| −3 | 00001001 |  
| +3.5 | 00000110 |  
| −3.5 | 00000111 |  

这些代码表明显类似于“真”哈夫曼代码，因为每个符号都被分配了一个唯一的码字，公共符号被分配了较短的码字，并且在一个表中，没有任何码字是任何其他码字的前缀。与“真实”哈夫曼编码的主要区别在于：（a）码字是基于“通用”概率分布预先计算的；（b）在TCOEF的情况下，只有102个常见符号定义了码字，而任何其他符号都是使用固定长度编码的。

#### 3.5.2.3 其他变长编码 

除了哈夫曼和基于哈夫曼的代码外，许多其他VLC家族也对视频编码应用感兴趣。用于编码数据传输的基于哈夫曼码的一个严重缺点是，它们对传输错误非常敏感。VLC序列中的错误可能导致解码器失去同步并无法正确解码后续代码，从而导致解码序列中的错误传播或传播。可逆vlc（rvlc）可以在前向或后向成功解码，可以在错误发生时显著提高解码性能。表3.6和表3.7等预定义代码表的一个缺点是编码器和解码器必须以某种形式存储该表。另一种方法是，如果输入符号已知，则使用可“动态”自动生成的代码。指数Golomb码（Exp-Golomb）属于这一类，在第7章中有描述。

### 3.5.3 算术编码

第3.5.2节中描述的可变长度编码方案具有一个基本缺点，即为每个符号分配包含整数位数的码字是次优的，因为符号的最佳位数取决于信息内容，通常是小数。对于概率大于0.5的符号，可变长度代码的压缩效率特别差，因为可以达到的最佳效果是用一个位代码表示这些符号。

算术编码为哈夫曼编码提供了一种实用的替代方案，可以更接近理论上的最大压缩比[ix]。算术编码器将数据符号序列转换为单个小数，并可接近表示每个符号所需的最佳小数位数。

**示例**

表3.8列出了五个运动矢量值(−2.−1,0,1,2）以及第3.5.2.1节示例1中的概率。根据每个向量的出现概率，在0.0到1.0范围内为其分配一个子范围。在这个例子中(−2） 概率为0.1，子范围为0–0.1，即总范围0到1.0的前10%(−1） 概率为0.2，并给出总范围的下一个20%，即子范围0.1–0.3。将子范围分配给每个向量后，总范围0–1.0已根据其概率在数据符号（向量）之间划分（图3.49）。

![Figure 3.49 Arithmetic coding example](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.49.PNG?raw=true)

每次编码符号时，范围（L到H）逐渐变小。在编码过程的最后，即本例中的四个步骤中，我们只剩下一个最终范围（L到H）。数据符号的整个序列可以通过传输位于该最终范围内的任何小数来表示。在上面的例子中，我们可以发送0.3928到0.396范围内的任何数字：例如，0.394。图3.50显示了在处理每个数据符号时，如何将初始范围（0，1）逐步划分为更小的范围。对第一个符号矢量0进行编码后，新范围为（0.3,0.7）。下一个符号（矢量–1）选择子范围（0.34、0.42），该子范围将成为新范围，依此类推。最后一个符号vector+2选择子范围（0.3928、0.396），并传输该范围内的数字0.394。0.394可以表示为使用9位的定点小数，因此我们的数据序列（0，−1、0、2）压缩为9位量。

Table 3.8 Motion vectors, sequence 1: probabilities and sub-ranges

| Vector | Probability | log2(1/P) | Sub-range |  
| :----: | :---------: | :-------: | :-------: |  
| −2 | 0.1 | 3.32 | 0–0.1 |  
| −1 | 0.2 | 2.32 | 0.1–0.3 |  
| 0 | 0.4 | 1.32 | 0.3–0.7 |  
| 1 | 0.2 | 2.32 | 0.7–0.9 |  
| 2 | 0.1 | 3.32 | 0.9–1.0 |  

![Figure 3.50 Sub-range example](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.50.PNG?raw=true)

编码矢量序列(0, -1, 0, 2)的过程

| Encoding procedure | Range(L->H) | Symbol | Sub-range (L->H) | Notes |  
| :----: | :----: | :----: | :---: | :----: |  
| 1. Set the initial range | 0->1.0 | | | |   
| 2. For the first data symbol, find the corresponding sub-range (Low to High). | | (0) | 0.3->0.7 |  |  
| 3. Set the new range(1) to this sub-range | 0.3->0.7 | | | |  
| 4. For the next data symbol, find the sub-range L to H | | (-1) | 0.1->0.3 | This is the sub-range within the interval 0 - 1 |  
| 5. Set the new range (2) to this sub-range within the previous range | 0.34->0.42 |  | |0.34 is 10% of the range; 0.42 is 30% of the range |  
| 6. Find the next sub-range |  |  (0) | 0.3->0.7 |  |  
| 7. Set the new range (3) within the previous range | 0.364→0.396 |  | | 0.364 is 30% of the range; 0.396 is 70% of the range |  
| 8. Find the next sub-range | | (2) | 0.9->0.1 | |  
| 9. Set the new range (4) within the previous range | 0.3928→0.396 | | | 0.3928 is 90% of the range; 0.396 is 100% of  the range |  

**解码过程**

| Decoding procedure | Range | Sub-range | Decoded symbol |  
| :----: | :----: | :----: | :---: |   
| 1. Set the initial range | 0->1 | | |  
| 2. Find the sub-range in which the received number falls. This indicates the first data symbol | | 0.3->0.7 | (0) |  
| 3. Set the new range (1) to this sub-range | 0.3->0.7 |  | |  
| 4. Find the sub-range of the new range in which the received number falls. This indicates the second data symbol. | | 0.34->0.42 | (-1) |  
| 5. Set the new range (2) to this sub-range within the previous range | 0.34->0.42 | | |  
| 6. Find the sub-range in which the received number falls and decode the third data symbol. | | 0.364->0.396 | (0) |  
| 7. Set the new range (3) to this sub-range within the previous range | 0.364->0.396 | | |  
| 8. Find the sub-range in which the received number falls and decode the fourth data symbol. | | 0.3928->0.396 | |  

算术编码的主要优点是，在这种情况下，传输的数字0.394（可使用9位以足够精度表示为定点数字）不受每个传输数据符号的整数位数的限制。为实现最佳压缩，数据符号序列应表示为：`log2(1/P0) + log2(1/P−1) + log2(1/P0) + log2(1/P2) bits = 8.28 bits` 在本例中，算术编码达到9位，接近最佳值。对每个数据符号使用整数位数的方案（如哈夫曼编码）不太可能接近最佳位数，并且通常，算术编码的性能优于哈夫曼编码。

#### 3.5.3.1 基于上下文的算术编码

成功的熵编码依赖于符号概率的精确模型。基于上下文的算术编码（CAE）使用局部空间和/或时间特征来估计要编码的符号的概率。CAE在JBIG标准中用于两级图像压缩，并已被用于编码MPEG-4视频中的二进制形状“掩码”，以及H.264某些配置文件中的熵编码（第7章）。

## 3.6 DPCM/DCT 混合视频编解码模型

自 20 世纪 90 年代初以来发布的主要视频编码标准基于相同的通用设计或视频编解码器模型，该视频编解码器包含运动估计和补偿第一阶段，有时称为 DPCM、变换阶段和熵编码器。该模型通常被描述为 DPCM/DCT 混合编解码器。与 H.261、H.263、MPEG-1、MPEG-2、MPEG-4 Visual、H.264/AVC 或 VC-1 兼容的任何编解码器都必须实现一组类似的基本编码和解码功能，尽管标准之间和实现之间在细节上存在许多差异。

![Figure 3.51 DPCM/DCT video encoder](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.51.PNG?raw=true)

图 3.51 和 图 3.52 显示了基本的 DPCM/DCT 混合编码器和解码器。在编码器中，处理视频帧 n(Fn)以产生编码或压缩比特流。在解码器中，如图右侧所示的压缩比特流被解码以产生重构视频帧F'n。重构的输出帧通常与源帧不同。这些图是特意绘制的，以突出编码器和解码器中的公共元素。解码器的大部分功能时机上包含在编码器中，其原因将在后面解释。

![Figure 3.52 DPCM/DCT video decoder](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.52.PNG?raw=true)

**Encoder data flow**

编码器中有两条主要的数据流路径，从左到右(编码)和从右到左(重建)。编码流程如下：  
1. 输入视频帧 Fn 用于编码，并以宏块为单位进行处理，对应于视频图像的 16x16 像素区域。  
2. Fn 与参考帧进行比较，例如先前编码的帧(F'<sub>n-1</sub>)。运动估计函数在 F'<sub>n-1</sub> 中找到一个 16x16 区域，与 F<sub>n</sub> 中的当前宏块相匹配。当前宏块位置和所选参考区域之间的偏移是运动矢量 MV。
3. 基于所选定的运动矢量 MV，生成运动补偿预测 P，由运动估计器选择 16x16 区域。P 可以由内插的亚像素数据组成。
4. 从当前宏块中减去P以产生残差或差分宏块D。
5. D 使用 DCT 变换。通常，D 被分成 8x8 或 4x4 个子块，每个子块分别变换。
6. 每个子块被量化（X）。
7. 对每个子块的 DCT 系数进行重新排序和运行级编码。
8. 最后，对每个宏块的系数、运动矢量和相关联的报头信息进行熵编码以产生压缩比特流。

重建数据流程如下：  
1. 每个量化宏块 X 被重新缩放和逆变换以产生解码的残余 D'。注意，不可逆量化过程意味着 D' 与 D 不同，即引入了失真。
2. 将运动补偿预测 P 添加到残差 D' 以产生重构宏块。重构宏块被组合以产生重构帧 F'n。

在编码完整帧之后，重构帧 F'n 可以用作下一帧 F<sub>n+1</sub> 的参考帧。

**Decoder data flow**

1. 对压缩后的比特流进行熵解码，提取每个宏块的系数、运动矢量和报头。
2. 运行级编码和重新排序被反转以产生量化的、变换的宏块 X。
3. 对 X 进行重新缩放和逆变换，以产生解码后的残差 D'。
4. 解码后的运动矢量用于定位前一(参考)帧 F'<sub>n-1</sub> 的解码器副本中的 16x16 区域。该区域称为运动补偿预测 P。
5. 将 P 添加到 D' 以产生重构宏块。重建的宏块被保存以产生解码帧 F'n。

在一个完整的帧被解码之后，F'n 准备好被显示，并且也可以被存储为下一个解码帧 F'<sub>n-1</sub> 的参考帧。

从图和上述说明可以清楚地看出，编码器包括解码路径：重缩放、IDCT、重构。这对于确保编码器和解码器使用相同的参考帧 F'<sub>n-1</sub> 是必要的用于运动补偿预测。

**示例**

使用 DPCM/DCT 编解码器对 CIF 格式的 25Hz 视频序列进行编码和解码，每帧都有 352x288 个亮度样本和 176x144 个红蓝色度样本。图 3.53 显示了要编码的 CIF 视频帧(Fn)，图 3.54 显示了重建的前一帧 F'<sub>n-1</sub>。注意，F'<sub>n-1</sub> 已被编码和解码，并显示一些失真。假设没有运动补偿（图3.55），Fn 和 F'<sub>n-1</sub> 的区别仍然包含大量能量，尤其是在运动区域的边缘。

![Figure 3.53 Input frame Fn](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.53.PNG?raw=true)

![Figure 3.54 Reconstructed reference frame F'(n-1)](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.54.PNG?raw=true)

![Figure 3.55 Residual Fn-F’n−1 : no motion compensation](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.55.PNG?raw=true)

运动估计以 16x16 块大小和半像素精度进行，产生如图 3.56 所示的向量表，为清晰起见叠加在当前帧上。许多向量为零并显示为点，这意味着当前宏块的最佳匹配在参考帧中的相同位置；在移动区域周围，向量指向块移动的方向。左边的那个人正在往左边走；因此，向量指向右边，即它来自哪里。有些矢量似乎与“真实”运动不对应，例如在桌子表面上，但仅表明最佳匹配不再参考帧中的同一位置。像此类的噪声向量通常出现在图片的同质区域，在这些区域中，参考帧中没有清晰的对象特征。

![Figure 3.56 16 × 16 motion vectors superimposed on frame](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.56.PNG?raw=true)

运动补偿参考帧(图3.57)是根据运动矢量“重组”的参考帧。例如，请注意，行走的人已向左移动，以便为当前帧中的同一人提供更好的匹配，儿最左侧的人的手已向下移动，以便提供更好的匹配。从当前帧中减去运动补偿参考帧得到图 3.58 中的运动补偿残差，其中能量明显降低，尤其是在运动区域周围。

![Figure 3.57 Motion compensated reference frame](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.57.PNG?raw=true)

![Figure 3.58 Motion compensated residual frame](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.58.PNG?raw=true)

图 3.59 显示了原始帧的宏块，取自右侧人物头部周围；图 3.60 显示了运动补偿后的亮度剩余。将 2D DCT 应用于亮度样本的右上 8x8 块(表 3.9)，产生表 3.10 中列出的 DCT 系数。各系数的大小如图 3.61 所示；请注意，较大的系数聚焦在左上角(DC)系数周围。

![Figure 3.59 Original macroblock : luminance](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.59.PNG?raw=true)

Table 3.9 Residual luminance samples : top-right 8 × 8 block

| -4 | -4 | -1 | 0 | 1 | 1 | 0 | -2 |  
| :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: | 
| 1 | 2 | 3 | 2 | −1 | −3 | −6 | −3 |  
| 6 | 6 | 4 | −4 | −9 | −5 | −6 | −5 | 
| 10 |8 | −1 | −4 | −6 | −1 | 2 | 4 |  
| 7 | 9 | −5 | −9 | −3 | 0 | 8 | 13 |  
| 0 | 3 | −9 | −12 | −8 | −9 | −4 | 1 |  
| −1 | 4 | −9 | −13 | −8 | −16 | −18 | −13 |  
| 14 | 13 | −1 | −6 | 3 | −5 | −12 | −7 |  

Table 3.10 DCT coefficients

| −13.50 | 20.47 | 20.20 | 2.14 | −0.50 | −10.48 | −3.50 | −0.62 |  
| :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |   
| 10.93 |−11.58 | −10.29 | −5.17 | −2.96 | 10.44 | 4.96 | −1.26 |    
| −8.75 | 9.22 | −17.19 | 2.26 | 3.83 | −2.45 | 1.77 | 1.89 |    
| −7.10 | −17.54 | 1.24 | −0.91 | 0.47 | −0.37 | −3.55 | 0.88 |  
| 19.00 | −7.20 | 4.08 | 5.31 | 0.50 | 0.18 | −0.61 | 0.40 |  
| −13.06 | 3.12 | −2.04 | −0.17 | −1.19 | 1.57 | −0.08 | −0.51 |  
| 1.73 | −0.69 | 1.77 | 0.78 | −1.86 | 1.47 | 1.19 | 0.42 |  
| −1.99 | −0.05 | 1.24 | −0.48 | −1.86 | −1.17 | −0.21 | 0.92 |  

![Figure 3.60 Residual macroblock : luminance](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.60.PNG?raw=true)

![Figure 3.61 DCT coefficient magnitudes : top-right 8 × 8 block](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.61.PNG?raw=true)

应用一个简单的前向量化器：Qcoeff = round(coeff/Qstep)。其中 Qstep 是量化器步长，在本例中为 12。量化块中的小值系数变为零(表 3.11),非零输出聚集在左上角(DC)系数周围。  

量化块在左上角开始的锯齿形扫描中重新排序，以产生线性阵列： −1, 2, 1, −1, −1, 2, 0, −1, 1, −1, 2, −1, −1, 0, 0, −1, 0, 0, 0, −1, −1, 0, 0, 0, 0, 0, 1, 0, . . .

Table 3.11 Quantized coefficients

| -1 | 2 | 2 | 0 | 0 | -1 | 0 | 0 |  
| :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |   
| 1 | −1 | −1 | 0 | 0 | 1 | 0 | 0  |   
|−1 | 1  | −1 | 0 | 0 | 0 | 0 | 0  |   
| −1| −1 | 0 | 0 | 0 | 0 | 0 | 0 |   
| 2 | −1 | 0 | 0 | 0 | 0 | 0 | 0 |   
| -1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |   
| 0  | 0 | 0 | 0 | 0 | 0 | 0 | 0 |   
| 0  | 0 | 0 | 0 | 0 | 0 | 0 | 0 |   

处理此数组以生成一系列（zero run, level）对：(0, −1)(0, 2)(0, 1)(0, −1)(0, −1)(0, 2)(1, −1)(0, 1)(0, −1)(0, 2)(0, −1)(0, −1)(2, −1)(3, −1)(0, −1)(5, 1)(EOB)。EOB（结束块）表示剩余系数为零。每个(run, level)对 编码为 VLC。使用 MPEG-4 可视 TCOEF 表(表3.6)，生成表 3.12 中的所示的VLC。

Table 3.12 Variable length coding example

| Run, Level, Last |  VLC including sign bit |  
| :---: | :---: |  
| (0,−1, 0) | 101 |  
| (0,2, 0)  | 11100 |  
| (0,1, 0)  | 100 |  
| (0,−1, 0) | 101 |  
| (0,−1, 0) | 101 |  
| (0,2, 0)  | 11100 |  
| (1,−1, 0) | 1101 |  
| (5,1, 1)  | 00100110 |  

最后的 VLC 信号 LAST=1，表示这是块的结束。该宏块的运动矢量为(0, 1)，即矢量指向下方。基于相邻宏块的预测矢量为(0, 0)，因此运动矢量差值为 MVDx = 0，MVDy = +1。使用 MPEG4 MVD 表（表3.7），将其分别编码为(1)和(0010)。

宏块作为一系列 VLC 传输，包括每个 8x8 块的宏块头部、运动矢量差(x, y)和变换系数(TCOEF)。

在解码器端，对 VLC 序列进行解码，以提取每个块的头系数、MVDx 和 MVDy以及(run，level)对。通过在每个(level)之前插入(run)零来重构重新排序系数的 64 元素数组。然后对阵列进行排序，以产生与 表 3.11 相同的 8x8 块。量化系数使用以下方法重新缩放：  Rcoeff = Qstep.Qcoeff。

如前所述，Qstep = 12 会产生如表 3.13 中所示的系数块。注意，由于量化过程该块与原始 DCT 系数(表3.10)显著不同。应用逆 DCT 创建解码后的残差块(表 3.14),其与原始残差块(表3.9)相似但不相同。原始和解码后的剩余块在图 3.62 中并排绘制，很明显，由于量化后的高频 DCT 系数损失，解码后的块具有较少的高频变化。

Table 3.13 Rescaled coefficients

| -12 | 24 | 24 | 0 | 0 | -12 | 0 | 0 |  
| :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  
| 12 | −12 | −12 | 0 | 0 | 12 | 0 | 0 |  
|−12 | 12  | −12 | 0 | 0 | 0  | 0 | 0 |  
| −12| −12 | 0 | 0 | 0 | 0 | 0 | 0 |  
| 24| −12 | 0 | 0 | 0 | 0 | 0 | 0 |  
| −12| 0 | 0 | 0 | 0 | 0 | 0 | 0 |  
| 0| 0 | 0 | 0 | 0 | 0 | 0 | 0 |  
| 0| 0 | 0 | 0 | 0 | 0 | 0 | 0 |  

Table 3.14 Decoded residual luminance samples

| −3 | −3 | −1 | 1  | −1 | −1 | −1 | −3  |  
| :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  :---: |  
| 5  | 3  | 2  | 0  | −3 | −4 | −5 | −6  |  
| 9  | 6  | 1  | −3 | −5 | −6 | −5 | −4  |  
| 9  | 8  | 1  | −4 | −1 | 1  | 4  | 10  |  
| 7  | 8  | −1 | −6 | −1 | 2  | 5  | 14  |  
| 2  | 3  | −8 | −15| −11| −11| −11| −2  |  
| 2  | 5  | −7 | −17| −13| −16| −20| −11 |  
| 12 | 16 | 3  | −6 | −1 | −6 | −11| −3  |  

解码器基于先前解码的向量形成其自己的预测运动向量，并重新创建原始运动向量（0，1）。使用这个向量，连同它自己的先前解码帧F'n-1的副本，解码器重构宏块。完整的解码帧如图3.63所示。由于量化过程，引入了一些失真，例如，在白板上的面和方程等详细区域周围，沿8×8块边界有一些明显的边缘。整个序列被压缩了大约300倍，即编码序列所占空间小于未压缩视频大小的1/300，因此以相对较差的图像质量为代价实现了显著的压缩。

![Figure 3.62 Comparison of original and decoded residual blocks](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.62.PNG?raw=true)

![Figure 3.63 Decoded frame F'n](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.63.PNG?raw=true)

## 3.7 总结

本章描述的视频编码工具，运动补偿预测、变换编码、量化和熵编码，构成了可靠和有效的编码模型的基础，该模型在视频压缩领域占据主导地位超过 10 年。这个编码模型是 H.264/AVC 标准的核心。下一章介绍了 H.264/AVC 的主要特性，并在接下来的章节中详细讨论了该标准。


