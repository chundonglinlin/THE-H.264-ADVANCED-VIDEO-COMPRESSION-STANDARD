# 视频编码概念

## 3.1 引言

**compress vb.: to squeeze together or compact into less space; condense**  
**compression noun: the act of compression or the condition of being compressed**

压缩是将数据压缩成更少 bit 的行为过程。视频压缩(视频编码)是将数字视频转换成适合传输或存储的格式的过程,同时通常会减少比特数。原始视频(未压缩视频)通常需要非常大的比特率，如第二章中的 216Mbit/s。因此，压缩对于数字视频的实际存储和传输是必要的。

压缩涉及一对互补的系统，一个压缩器(编码器)和一个解压器(解码器)。编码器在传输或存储之前，将源数据转换成占用较少比特数的压缩形式，解码器将压缩形式转换回原始视频数据。编码器/解码器对通常被描述为编解码器(编解码器)(图 3.1)。

![Figure 3.1 Encoder/Decoder](https://github.com/lazybing/THE-H.264-ADVANCED-VIDEO-COMPRESSION-STANDARD/blob/main/image/Figure3.1.png?raw=true)

数据压缩是通过消除冗余来实现的，即消除那些数据的重建并不是必须的组件。数据的许多类型包含统计冗余，并且可以使用无损压缩进行有效压缩，这种情况，解码器端输出的重建数据是原始数据的完美副本。不幸的是，图像和视频信息的无损压缩只能提供中等程度的压缩。无损图像压缩标准(例如JPEG-LS)能够实现的最大压缩率是3-4倍左右。有损压缩对于实现高压缩率是由必要的。在有损压缩系统中，解压缩后的数据与原数据不相同，并且以视觉质量损失为代价来实现更高的压缩比。有损视频压缩系统基于去除主观冗余的原理，即图像或视频序列中的元素可以在不显著影响观看者对视觉质量的感知情况下被去除。

大多数视频编码方法利用时间和空间冗余来实现压缩。在时域中，几乎同时被捕获的视频帧之间通常高度的相似性或相关性。时间上相邻的帧，即时间顺序上的连续帧，通常高度相关，特别是在时间采样率或帧率高的情况下。在空间域中，彼此接近的像素（样本）之间通常存在高度相关性，即相邻样本的值通常非常相似（图3.2）。

H.264高级视频编码标准与其他流行的压缩格式（如MPEG-2视频、MPEG-4视频、H.263、VC-1等）共享许多共同的特性。这些格式中的每一种都是基于使用预测和/或基于块的运动补偿、变换、量化和熵编码的编解码器“模型”。在这一章中，我们研究了该模型的主要组成部分，从预测模型开始，包括帧内预测、运动估计和运动补偿，接着是图像变换、量化、预测编码和熵编码。本章最后介绍了基本模型的“演变”，接着介绍了对图像样本块进行编码和解码的过程。

## 3.2 Video CODEC

视频编解码器（图 3.3）将源图像与视频序列编码为压缩形式，并对其进行解码以产生源序列的副本或近似值。如果解码的视频序列与原视频序列相同，则编码过程是无损的；如果解码序列与原始序列不同，则该过程是有损的。

编解码器通过**模型**表示原视频序列，这是一种高效的编码表示，可用于重建视频数据的近似值。理想情况下，模型应该使用尽可能少的比特和尽可能高的保真度来表示序列。压缩效率和高质量这两个目标通常是冲突的，即较低的压缩比特率通常在解码器处产生降低的图像质量。

视频编码器（图3.3）由三个主要功能单元组成：**预测模型**、**空间模型**和**熵编码器**。预测模型的输入是未压缩的原始视频序列。预测模型试图通过利用相邻视频帧和/或相邻图像样本之间的相似性来减少冗余，通常通过构建当前视频帧或视频数据块的预测。在 H.264/AVC 中，根据当前帧或一个或多个先前和/或未来帧中的数据形成预测。它是通过相邻图像样本进行空间外推、帧内预测或通过补偿帧间差异、帧间或运动补偿预测来创建的。预测模型的输出是通过从实际的当前帧减去预测而产生的残余帧，以及指示帧内预测类型或描述如何补偿运动的一组模型参数。

残差帧形成了空间模型的输入，利用残差帧中的局部样本之间的相似性来减少空间冗余。在 H.264/AVC 中，这是通过对残余样本应用变换并量化结果来实现的。变换将样本转换为另一个域，在该域中它们由变换系数表示。系数被量化以去除不重要的值，留下少量的重要系数，其提供剩余帧的更紧凑表示。空间模型的输出是一组量化的变换系数。

预测模型的参数（即帧内预测模式或帧间预测模式和运动矢量）、以及空间模型（即系数）由熵编码器压缩。这消除了数据中的统计冗余，例如用短二进制码表示通常出现的向量和系数。熵编码器产生可被传输和/或存储的压缩比特流或文件。压缩序列由编码预测参数、编码残差系数和头信息组成。

视频解码器从压缩比特流重构视频帧。通过上解码器对系数和预测参数进行解码，然后对空间模型进行解码以重构残差帧的版本。解码器使用预测参数以及先前解码的图像像素来创建当前帧的预测，并通过将剩余帧添加到该预测中的重构帧本身。

## 3.3 预测模型

要处理的数据是当前帧或场中的一组图像样本。预测模型的目标是通过形成数据的预测并从当前数据中减去该预测来降低冗余。预测可能来自先前编码的帧(时间预测)或同一帧中先前编码的图像样本（空间预测）。该过程的输出是一组残差或差分样本，预测过程越精确，残差中包含的能量就越少。残差被编码并发送到解码器，解码器重建相同的预测，以便它可以添加解码残差并重构当前帧。为了解码器能够创建相同的预测，编码器必须使用解码器可用的数据，即已经编码和发送的数据来形成预测。

### 3.3.1 时域预测

预测帧是从一个或多个过去、将来的帧（称为参考帧）创建出的。通常可以通过补偿参考帧和当前帧之间的运动来提高预测精读。

#### 3.3.1.1 从之前帧预测

时间预测最简单方法是使用前一帧作为当前帧的预测器。一个视频序列的两个连续帧如图 3.4 和图 3.5 所示。第 1 帧作为第 2 帧的预测器，从当前帧(第 2 帧)减去预测器(第 1 帧)形成的残差如图 3.6 所示。在该图像中，中灰色表示差值为零，而浅灰色或深灰色分别对应于正差值和负差值。简单预测的明显问题是，在剩余帧（由亮区和暗区表示）中仍然存在大量能量，这意味着在时间预测之后仍然有大量信息要压缩。大部分剩余能量是由于两针之间的物体运动引起的，通过补偿两帧之间的运动可以形成更好的预测。

#### 3.3.1.2 运动引起的变换

视频帧之间变换的原因包括运动、未覆盖区域和光照变化。运动类型包括刚性物体运动（例如移动的汽车）、可变性物体运动（例如说话的人）和相机运动（例如平移、倾斜、变焦和旋转）。未覆盖区域可能是被移动物体覆盖的场景背景的一部分。除了未覆盖区域和光照变化之外，这些差异对应于帧之间的像素移动。可以估计连续帧之间的每个像素的轨迹，产生称之为光流的像素轨迹场。图 3.7 显示了图 3.4 和图 3.5 框架的光流场。完整的场包括每个像素位置的流矢量，但是为了清楚起见，对场进行了子采样，以便仅显示每 2 个像素的矢量。

如果准确地知道光流场，则可以沿着光流矢量从参考帧移动每个像素来形成对当前帧的大多数像素的准确预测。然而，这不是一种实用的运动补偿方法，原因有几个。光流的精确计算是非常计算密集的，因为更精确的方法会对每个像素都使用迭代过程，并且对于解码器重建预测帧，将有必要将每个像素的光流矢量发送到解码器，从而产生大量传输数据并降低小残差的优点。

#### 3.3.1.3 基于块的运动估计与补偿

一种实用并且被广泛使用的运动补偿方法是补偿当前帧的矩形部分或“块”的运动。对当前帧中的每个 MxN 样本块执行以下步骤：

* 搜索参考帧中的某个区域（过去或未来帧），以找到近似的 MxN 采样区域。可通过将当前帧中的 MxN 块与搜索区域中的一些或所有可能的MxN 区域（例如，以当前块位置为中心的区域）进行比较，并找到给出“最佳”匹配的区域来执行该搜索。一种流行的匹配准则是从当前的 MxN 块中减去候选区域所形成的残差中的能量，从而选择残差能量最小的候选区域作为最佳匹配。这种寻找最佳匹配的过程称为**运动估计**。  
* 所选的候选区域成为当前 MxN 块的预测器（运动补偿预测），并且从当前块中减去该候选区域形成剩余 MxN 块（**运动补偿**）。  
* 对剩余块进行编码和发送，并且还发送当前块与候选区域（**运动矢量**）的位置之间的偏移。  

解码器使用接收到的运动矢量来重新创建预测器区域。它对剩余块进行解码，将其添加到预测器中，并重建原始块的版本。

基于块的运动补偿是有许多原因的。它相对简单且易于计算，适合于矩形视频帧和基于块的图像变换（如离散余弦变换），为许多视频序列提供了合理有效的时间模型。但也有一些缺点。例如，“真实”对象很少有与矩形边界匹配的整齐边缘，对象通常在帧之间以小数点的像素位置移动，并且许多类型的对象运动很难使用基于块的方法进行补偿，例如可变形对象、旋转、扭曲和复杂运动（如烟云）。尽管存在这些缺点，基于块的运动补偿仍然是当前所有视频编码标准所使用的时间预测模型的基础。

#### 3.3.1.4 宏块的运动补偿预测


